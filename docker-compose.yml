version: '3.8'

services:
  # =====================================================
  # PostgreSQL MDM Hub - Base de données principale
  # =====================================================
  postgres-mdm-hub:
    image: postgres:15-alpine
    container_name: postgres-mdm-hub
    environment:
      POSTGRES_DB: mdm_clinique
      POSTGRES_USER: mdm_user
      POSTGRES_PASSWORD: mdm_password
      PGDATA: /var/lib/postgresql/data/pgdata
    ports:
      - "5432:5432"
    volumes:
      - postgres_mdm_data:/var/lib/postgresql/data
      - ./sql/01-create-tables.sql:/docker-entrypoint-initdb.d/01-create-tables.sql
    networks:
      - mdm-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U mdm_user -d mdm_clinique"]
      interval: 10s
      timeout: 5s
      retries: 5

  # =====================================================
  # OpenMetadata - Base de données
  # =====================================================
  openmetadata-db:
    image: postgres:15-alpine
    container_name: openmetadata-db
    environment:
      POSTGRES_DB: openmetadata_db
      POSTGRES_USER: openmetadata_user
      POSTGRES_PASSWORD: openmetadata_password
    ports:
      - "5433:5432"
    volumes:
      - openmetadata_db_data:/var/lib/postgresql/data
    networks:
      - mdm-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U openmetadata_user -d openmetadata_db"]
      interval: 10s
      timeout: 5s
      retries: 5

  # =====================================================
  # Elasticsearch pour OpenMetadata
  # =====================================================
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: openmetadata-elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    networks:
      - mdm-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # =====================================================
  # OpenMetadata Server
  # =====================================================
  openmetadata-server:
    image: openmetadata/openmetadata-server:1.2.0
    container_name: openmetadata-server
    ports:
      - "8585:8585"
    environment:
      DB_DRIVER_CLASS: org.postgresql.Driver
      DB_HOST: openmetadata-db
      DB_PORT: 5432
      DB_USER: openmetadata_user
      DB_PASSWORD: openmetadata_password
      DB_DATABASE_SCHEMA: public
      ELASTICSEARCH_HOST: elasticsearch
      ELASTICSEARCH_PORT: 9200
      ELASTICSEARCH_SCHEME: http
      AUTHORIZER_CLASS_NAME: org.openmetadata.service.security.DefaultAuthorizer
      AUTHORIZER_REQUEST_FILTER: org.openmetadata.service.security.JwtFilter
      AUTHORIZER_ADMIN_PRINCIPALS: admin
      AUTHORIZER_PRINCIPAL_DOMAIN: open-metadata.org
      AUTHENTICATION_PROVIDER: no-auth
      PIPELINE_SERVICE_CLIENT_ENABLED: false
    depends_on:
      openmetadata-db:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
    networks:
      - mdm-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8585/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # =====================================================
  # Airflow - Base de données metadata
  # =====================================================
  airflow-db:
    image: postgres:15-alpine
    container_name: airflow-db
    environment:
      POSTGRES_DB: airflow
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
    ports:
      - "5434:5432"
    volumes:
      - airflow_db_data:/var/lib/postgresql/data
    networks:
      - mdm-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow -d airflow"]
      interval: 10s
      timeout: 5s
      retries: 5

  # =====================================================
  # Airflow - Redis (pour CeleryExecutor)
  # =====================================================
  airflow-redis:
    image: redis:7-alpine
    container_name: airflow-redis
    ports:
      - "6379:6379"
    networks:
      - mdm-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # =====================================================
  # Airflow - Webserver
  # =====================================================
  airflow-webserver:
    image: apache/airflow:2.8.0
    container_name: airflow-webserver
    depends_on:
      airflow-db:
        condition: service_healthy
      airflow-redis:
        condition: service_healthy
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow-db/airflow
      - AIRFLOW__CORE__FERNET_KEY=''
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth
      - AIRFLOW__WEBSERVER__SECRET_KEY=''
      - _PIP_ADDITIONAL_REQUIREMENTS=''
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/config:/opt/airflow/config
    ports:
      - "8080:8080"
    command: webserver
    networks:
      - mdm-network
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  # =====================================================
  # Airflow - Scheduler
  # =====================================================
  airflow-scheduler:
    image: apache/airflow:2.8.0
    container_name: airflow-scheduler
    depends_on:
      airflow-db:
        condition: service_healthy
      airflow-redis:
        condition: service_healthy
      airflow-webserver:
        condition: service_healthy
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow-db/airflow
      - AIRFLOW__CORE__FERNET_KEY=''
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth
      - AIRFLOW__WEBSERVER__SECRET_KEY=''
      - _PIP_ADDITIONAL_REQUIREMENTS=''
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/config:/opt/airflow/config
    command: scheduler
    networks:
      - mdm-network
    healthcheck:
      test: ["CMD-SHELL", 'airflow jobs check --job-type SchedulerJob --hostname "$${HOSTNAME}" || exit 1']
      interval: 30s
      timeout: 10s
      retries: 5

  # =====================================================
  # Airflow - Init DB (one-time initialization)
  # =====================================================
  airflow-init:
    image: apache/airflow:2.8.0
    container_name: airflow-init
    depends_on:
      airflow-db:
        condition: service_healthy
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow-db/airflow
      - AIRFLOW__CORE__FERNET_KEY=''
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
    entrypoint: /bin/bash
    command:
      - -c
      - |
        function ver() {
          printf "%04d%04d%04d%04d" $${1//./ }
        }
        if [ -e /opt/airflow/airflow.db ]; then
          echo "Airflow DB already exists, skipping initialization"
        else
          echo "Initializing Airflow DB..."
          airflow db init
          echo "Creating admin user..."
          airflow users create \
            --username admin \
            --firstname Admin \
            --lastname User \
            --role Admin \
            --email admin@example.com \
            --password admin
        fi
    networks:
      - mdm-network
    profiles:
      - init

  # =====================================================
  # Zookeeper (pour Kafka)
  # =====================================================
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_log:/var/lib/zookeeper/log
    networks:
      - mdm-network
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 2181 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # =====================================================
  # Kafka
  # =====================================================
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    ports:
      - "9092:9092"
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - mdm-network
    healthcheck:
      test: ["CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:9092 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

# =====================================================
# Volumes
# =====================================================
volumes:
  postgres_mdm_data:
    driver: local
  openmetadata_db_data:
    driver: local
  elasticsearch_data:
    driver: local
  airflow_db_data:
    driver: local
  zookeeper_data:
    driver: local
  zookeeper_log:
    driver: local
  kafka_data:
    driver: local

# =====================================================
# Networks
# =====================================================
networks:
  mdm-network:
    driver: bridge

