# Guide de D√©pannage Complet - Projet MDM

Ce guide r√©pertorie tous les probl√®mes courants rencontr√©s lors de l'installation et de l'utilisation du projet MDM, avec leurs solutions.

## üìã Table des mati√®res

1. [Erreurs de connexion OpenMetadata](#erreurs-de-connexion-openmetadata)
2. [Erreurs PostgreSQL](#erreurs-postgresql)
3. [Erreurs Airflow](#erreurs-airflow)
4. [Erreurs d'ingestion OpenMetadata](#erreurs-dingestion-openmetadata)
5. [Erreurs Elasticsearch](#erreurs-elasticsearch)
6. [Erreurs de Pipeline Service](#erreurs-de-pipeline-service)
7. [Tables vides dans OpenMetadata](#tables-vides-dans-openmetadata)
8. [Erreurs de DAG Airflow](#erreurs-de-dag-airflow)
9. [Probl√®mes de services Docker](#probl√®mes-de-services-docker)

## Erreurs de connexion OpenMetadata

### Erreur : "Failed to trigger workflow due to airflow API returned Internal Server Error" avec "Connection refused" sur `localhost:8585`

**Sympt√¥me** :
```
Failed to trigger workflow due to airflow API returned Internal Server Error and response {"error": "Error running automation workflow due to [HTTPConnectionPool(host='localhost', port=8585): Max retries exceeded with url: /api/v1/system/version (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7c3fd2310700>: Failed to establish a new connection: [Errno 111] Connection refused'))] "}
```

**Cause** : L'Airflow d'ingestion essaie de se connecter au serveur OpenMetadata via `localhost:8585` au lieu d'utiliser le nom du conteneur Docker (`openmetadata-server:8585`).

**Solution** : V√©rifiez que la variable d'environnement `SERVER_HOST_API_URL` est configur√©e dans `openmetadata-server` :

```bash
# V√©rifier la configuration
docker exec openmetadata-server env | grep SERVER_HOST_API_URL
```

Vous devriez voir :
```
SERVER_HOST_API_URL=http://openmetadata-server:8585/api
```

Si ce n'est pas le cas, red√©marrez le conteneur :

```bash
docker-compose --profile openmetadata restart openmetadata-server
```

**Documentation d√©taill√©e** : Voir [Configuration OpenMetadata](03-openmetadata-options.md#erreur-failed-to-trigger-workflow-due-to-airflow-api-returned-internal-server-error)

### Erreur : "Failed to connect to Airflow"

**Sympt√¥me** :
```
Failed to connect to Airflow due to java.net.ConnectException. Is the host available at http://openmetadata-ingestion:8080?
```

**Cause** : Le service `openmetadata-ingestion` n'est pas d√©marr√© ou la base de donn√©es Airflow n'est pas initialis√©e.

**Solution** :

1. **V√©rifier que le service est d√©marr√©** :
```bash
docker ps | grep openmetadata-ingestion
```

2. **Initialiser la base de donn√©es Airflow** :
```powershell
# Windows
.\scripts\init-openmetadata-airflow.ps1

# Linux/Mac
./scripts/init-openmetadata-airflow.sh
```

3. **Red√©marrer le service** :
```bash
docker-compose --profile openmetadata restart openmetadata-ingestion
```

**Documentation d√©taill√©e** : Voir [Configuration OpenMetadata](03-openmetadata-options.md#erreur-failed-to-connect-to-airflow)

## Erreurs PostgreSQL

### Erreur : "Failed to fetch queries, please validate if postgres instance has pg_stat_statements extension installed"

**Sympt√¥me** :
```
Failed to fetch queries, please validate if postgres instance has pg_stat_statements extension installed and the user has at least select privileges for pg_stat_statements table.
```

**Cause** : L'extension `pg_stat_statements` n'est pas activ√©e dans PostgreSQL.

**Solution** : L'extension est automatiquement configur√©e dans `docker-compose.yml` pour `postgres-mdm-hub`. Si vous avez des probl√®mes :

1. **V√©rifier que l'extension est install√©e** :
```bash
docker exec postgres-mdm-hub psql -U postgres -d mdm_clinique -c "SELECT extname, extversion FROM pg_extension WHERE extname = 'pg_stat_statements';"
```

2. **V√©rifier que shared_preload_libraries contient pg_stat_statements** :
```bash
docker exec postgres-mdm-hub psql -U postgres -d mdm_clinique -c "SHOW shared_preload_libraries;"
```

3. **Red√©marrer PostgreSQL si n√©cessaire** :
```bash
docker-compose restart postgres-mdm-hub
```

**Documentation d√©taill√©e** : Voir [Configuration OpenMetadata](03-openmetadata-options.md#erreur-failed-to-fetch-queries-please-validate-if-postgres-instance-has-pg_stat_statements-extension-installed)

### Erreur : "Connection refused" √† PostgreSQL

**Sympt√¥me** : Impossible de se connecter √† PostgreSQL depuis OpenMetadata.

**Solution** :

1. **V√©rifier que PostgreSQL est d√©marr√©** :
```bash
docker ps | grep postgres-mdm-hub
```

2. **V√©rifier la configuration dans OpenMetadata** :
   - Host : `postgres-mdm-hub` (nom du conteneur Docker, pas `localhost`)
   - Port : `5432` (port interne Docker)
   - Database : `mdm_clinique`
   - Username : `postgres`
   - Password : `root`

3. **Tester la connexion depuis OpenMetadata** :
   - Dans OpenMetadata UI : **Settings** > **Services** > **Databases** > **MDM Clinique Hub** > **Test Connection**

## Erreurs Airflow

### Erreur : "airflow-webserver exited (1)"

**Sympt√¥me** :
```
‚úò Container airflow-webserver Error
dependency failed to start: container airflow-webserver exited (1)
```

**Solution** : Voir [D√©pannage Airflow](04-depannage-airflow.md#1-erreur-airflow-webserver-exited-1)

### Erreur : "Database is not initialized"

**Solution** :
```bash
# Forcer la r√©initialisation
docker-compose --profile init up airflow-init --force-recreate
```

**Documentation d√©taill√©e** : Voir [D√©pannage Airflow](04-depannage-airflow.md#3-erreur-database-is-not-initialized)

## Erreurs d'ingestion OpenMetadata

### Erreur : "No DAG run found"

**Sympt√¥me** :
```
Failed to get last ingestion logs due to {"error": "No DAG run found for e02a3b57-dd5c-4417-a76e-4b59333f1270."}
```

**Cause** : Le pipeline d'ingestion n'a pas √©t√© ex√©cut√©. Le DAG existe mais aucun run n'a √©t√© cr√©√©.

**Solution** :

1. **D√©clencher manuellement le DAG** :
```bash
# Remplacer <DAG_ID> par l'ID de votre DAG d'ingestion
docker exec openmetadata-ingestion curl -s -u admin:admin -X POST -H 'Content-Type: application/json' -d '{}' http://localhost:8080/api/v1/dags/<DAG_ID>/dagRuns
```

2. **Via l'interface OpenMetadata** :
   - Allez dans **Settings** > **Services** > **Databases** > **MDM Clinique Hub**
   - Cliquez sur l'onglet **"Ingestion Pipelines"**
   - Cliquez sur le pipeline actif
   - Cliquez sur **"Run Now"**

3. **Via l'interface Airflow** :
   - Ouvrez http://localhost:8080
   - Trouvez votre DAG d'ingestion
   - Cliquez sur **"Trigger DAG"**

**Documentation d√©taill√©e** : Voir [Relancer ingestion colonnes vides](relancer-ingestion-colonnes-vides.md)

### Erreur : Tables vides sans colonnes

**Sympt√¥me** : Les tables sont visibles dans OpenMetadata mais n'ont pas de colonnes affich√©es.

**Solution** : Voir [Relancer ingestion colonnes vides](relancer-ingestion-colonnes-vides.md)

### Erreur : Tables vides sans donn√©es

**Sympt√¥me** : Les tables ont des colonnes mais pas de donn√©es d'√©chantillonnage (Sample Data).

**Solution** : Voir [Relancer ingestion colonnes vides](relancer-ingestion-colonnes-vides.md#configurer-et-lancer-le-profiler-agent-pour-voir-les-donn√©es)

## Erreurs Elasticsearch

### Erreur : "Search failed due to Elasticsearch exception"

**Sympt√¥me** :
```
Search failed due to Elasticsearch exception [type=search_phase_execution_exception, reason=all shards failed]
```

**Solution** :

1. **Red√©marrer Elasticsearch** :
```bash
docker-compose --profile openmetadata restart elasticsearch
Start-Sleep -Seconds 20
```

2. **Red√©marrer OpenMetadata Server** :
```bash
docker-compose --profile openmetadata restart openmetadata-server
Start-Sleep -Seconds 30
```

**Documentation d√©taill√©e** : Voir [Corriger Elasticsearch et Service](corriger-elasticsearch-et-service.md)

## Erreurs de Pipeline Service

### Erreur : "relation serialized_dag does not exist"

**Sympt√¥me** :
```
(psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
```

**Cause** : Vous avez configur√© **PostgreSQL** comme **Pipeline Service** au lieu d'**Airflow**.

**Solution** : Voir [Corriger Pipeline Service](corriger-pipeline-service.md)

### Erreur : "Issue in Search Entity By Key: fqnHash.keyword, Value Fqn: MDM Airflow Pipeline Service, Number of Hits: 0"

**Sympt√¥me** : Impossible de cr√©er un lineage entre Airflow et PostgreSQL.

**Cause** : OpenMetadata ne trouve pas le service Pipeline dans Elasticsearch.

**Solution** : Voir [Corriger Lineage Pipeline Database](corriger-lineage-pipeline-database.md)

### Erreur : DAGs Airflow non visibles dans OpenMetadata

**Sympt√¥me** : Le DAG `mdm_pipeline` est visible dans Airflow (port 8080) mais n'appara√Æt pas dans OpenMetadata.

**Solution** : Voir [Configurer Pipeline Service](configurer-pipeline-service-openmetadata.md)

## Tables vides dans OpenMetadata

### Tables sans colonnes

**Sympt√¥me** : Les tables sont visibles dans OpenMetadata mais n'ont pas de colonnes affich√©es.

**Solution** : Voir [Relancer ingestion colonnes vides](relancer-ingestion-colonnes-vides.md#solution-forcer-une-r√©ingestion-compl√®te)

### Tables sans donn√©es

**Sympt√¥me** : Les tables ont des colonnes mais pas de donn√©es d'√©chantillonnage (Sample Data).

**Solution** : Voir [Relancer ingestion colonnes vides](relancer-ingestion-colonnes-vides.md#configurer-et-lancer-le-profiler-agent-pour-voir-les-donn√©es)

## Erreurs de DAG Airflow

### Erreur : DAG non visible dans Airflow

**Sympt√¥me** : Le DAG `mdm_pipeline` n'appara√Æt pas dans l'interface Airflow.

**Solution** :

1. **V√©rifier que le DAG est dans le bon r√©pertoire** :
```bash
# V√©rifier que le fichier existe
docker exec openmetadata-ingestion ls -la /opt/airflow/dags/project_mdm/
```

2. **V√©rifier les logs Airflow** :
```bash
docker logs openmetadata-ingestion --tail 100 | grep -i "mdm_pipeline"
```

3. **V√©rifier la syntaxe du DAG** :
```bash
# Lancer un test de syntaxe Python
docker exec openmetadata-ingestion python -m py_compile /opt/airflow/dags/project_mdm/mdm_pipeline.py
```

4. **Red√©marrer Airflow** :
```bash
docker-compose restart openmetadata-ingestion
```

## Probl√®mes de services Docker

### Services ne d√©marrent pas

**Sympt√¥me** : Les services Docker ne d√©marrent pas ou s'arr√™tent imm√©diatement.

**Solution** :

1. **V√©rifier les logs** :
```bash
docker-compose logs -f
```

2. **V√©rifier l'√©tat des services** :
```bash
docker-compose ps
```

3. **V√©rifier l'utilisation des ressources** :
```bash
docker stats
```

4. **Red√©marrer un service sp√©cifique** :
```bash
docker-compose restart <service-name>
```

### Conflits de ports

**Sympt√¥me** : Erreur "port already in use" lors du d√©marrage des services.

**Solution** :

1. **Identifier le processus qui utilise le port** :
```powershell
# Windows
netstat -ano | findstr :8585

# Linux/Mac
lsof -i :8585
```

2. **Arr√™ter le processus ou modifier le port dans docker-compose.yml**

3. **Red√©marrer les services** :
```bash
docker-compose down
docker-compose up -d
```

### Probl√®mes de volumes Docker

**Sympt√¥me** : Les donn√©es ne persistent pas apr√®s red√©marrage ou erreur de permissions.

**Solution** :

1. **V√©rifier les volumes** :
```bash
docker volume ls
```

2. **V√©rifier les permissions** :
```bash
# Windows (PowerShell)
.\scripts\fix-airflow-permissions.ps1

# Linux/Mac
chmod -R 755 airflow/
```

3. **Supprimer et recr√©er les volumes** (‚ö†Ô∏è supprime les donn√©es) :
```bash
docker-compose down -v
docker-compose up -d
```

## Commandes utiles

### V√©rifier l'√©tat de tous les services

```bash
docker-compose ps
```

### Voir les logs d'un service

```bash
docker-compose logs -f <service-name>
```

### Red√©marrer tous les services

```bash
docker-compose restart
```

### Arr√™ter tous les services

```bash
docker-compose down
```

### Arr√™ter et supprimer les volumes (‚ö†Ô∏è supprime les donn√©es)

```bash
docker-compose down -v
```

### V√©rifier l'utilisation des ressources

```bash
docker stats
```

### Nettoyer les conteneurs arr√™t√©s

```bash
docker container prune
```

### Nettoyer les images non utilis√©es

```bash
docker image prune -a
```

## Documentation de r√©f√©rence

- [Configuration OpenMetadata](03-openmetadata-options.md)
- [D√©pannage Airflow](04-depannage-airflow.md)
- [Relancer ingestion colonnes vides](relancer-ingestion-colonnes-vides.md)
- [Corriger Elasticsearch et Service](corriger-elasticsearch-et-service.md)
- [Corriger Pipeline Service](corriger-pipeline-service.md)
- [Corriger Lineage Pipeline Database](corriger-lineage-pipeline-database.md)
- [Configurer Pipeline Service](configurer-pipeline-service-openmetadata.md)

## Besoin d'aide ?

Si vous ne trouvez pas la solution √† votre probl√®me dans ce guide :

1. V√©rifiez les logs des services : `docker-compose logs -f <service-name>`
2. Consultez la documentation sp√©cifique pour chaque service
3. V√©rifiez que tous les services sont d√©marr√©s : `docker-compose ps`
4. V√©rifiez l'utilisation des ressources : `docker stats`

