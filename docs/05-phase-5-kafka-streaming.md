# Phase 5 : Bonus - Streaming & Rapport

## √âtape 5.1 : Impl√©menter le Flux Temps R√©el (Kafka)

### Objectif

Montrer que votre MDM peut g√©rer les batchs (via Airflow) et le temps r√©el (via Kafka) pour les nouvelles inscriptions de patients.

### 1. Pr√©parer Kafka : Cr√©er votre Topic

#### M√©thode 1 : Via le script automatique (Recommand√©)

**Windows (PowerShell)** :
```powershell
.\scripts\create-kafka-topic.ps1
```

**Linux/Mac (Bash)** :
```bash
chmod +x scripts/create-kafka-topic.sh
./scripts/create-kafka-topic.sh
```

#### M√©thode 2 : Cr√©ation manuelle

**Option A : Via le conteneur Kafka directement**

```bash
# Entrer dans le conteneur Kafka
docker exec -it kafka bash

# Une fois √† l'int√©rieur du conteneur, cr√©er le topic
kafka-topics --create \
  --topic new_patient_registrations \
  --bootstrap-server localhost:9092 \
  --partitions 1 \
  --replication-factor 1

# V√©rifier que le topic est cr√©√©
kafka-topics --list --bootstrap-server localhost:9092

# Taper exit pour quitter le conteneur
exit
```

**Option B : Depuis l'h√¥te (sans entrer dans le conteneur)**

```powershell
# Windows (PowerShell)
docker exec kafka kafka-topics --create `
  --topic new_patient_registrations `
  --bootstrap-server localhost:9092 `
  --partitions 1 `
  --replication-factor 1

# V√©rifier
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092
```

```bash
# Linux/Mac (Bash)
docker exec kafka kafka-topics --create \
  --topic new_patient_registrations \
  --bootstrap-server localhost:9092 \
  --partitions 1 \
  --replication-factor 1

# V√©rifier
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092
```

### 2. V√©rifier que le topic est cr√©√©

```powershell
# Lister tous les topics
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092

# Afficher les d√©tails du topic
docker exec kafka kafka-topics --describe --topic new_patient_registrations --bootstrap-server localhost:9092
```

**R√©sultat attendu** :
```
Topic: new_patient_registrations
TopicId: xxxxx
PartitionCount: 1
ReplicationFactor: 1
Configs:
```

### 3. Tester le topic (Optionnel mais recommand√©)

#### Publier un message (Producer)

Dans un terminal :
```powershell
# Windows (PowerShell)
docker exec -it kafka kafka-console-producer --topic new_patient_registrations --bootstrap-server localhost:9092
```

```bash
# Linux/Mac (Bash)
docker exec -it kafka kafka-console-producer --topic new_patient_registrations --bootstrap-server localhost:9092
```

Tapez un message de test (ex: `{"id": "123", "nom": "Test", "prenom": "Patient"}`) et appuyez sur Entr√©e.

Pour quitter, tapez `Ctrl+C`.

#### Consulter les messages (Consumer)

Dans un autre terminal :
```powershell
# Windows (PowerShell)
docker exec -it kafka kafka-console-consumer --topic new_patient_registrations --from-beginning --bootstrap-server localhost:9092
```

```bash
# Linux/Mac (Bash)
docker exec -it kafka kafka-console-consumer --topic new_patient_registrations --from-beginning --bootstrap-server localhost:9092
```

Vous devriez voir le message que vous avez publi√©.

Pour quitter, tapez `Ctrl+C`.

### 4. Pr√™t pour le Job Talend

Une fois le topic cr√©√©, vous pouvez cr√©er votre job Talend qui :
1. √âcoute le topic `new_patient_registrations` avec `tKafkaInput`
2. Nettoie les donn√©es avec `tMap`
3. Fait un lookup dans la table `MDM_Patient` pour voir si le patient existe
4. Ins√®re ou met √† jour dans `MDM_Patient` avec `tDBOutput`

### Commandes utiles

#### Lister tous les topics
```powershell
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092
```

#### D√©tails d'un topic
```powershell
docker exec kafka kafka-topics --describe --topic new_patient_registrations --bootstrap-server localhost:9092
```

#### Supprimer un topic
```powershell
docker exec kafka kafka-topics --delete --topic new_patient_registrations --bootstrap-server localhost:9092
```

#### Compter les messages dans un topic
```powershell
docker exec kafka kafka-run-class kafka.tools.GetOffsetShell --broker-list localhost:9092 --topic new_patient_registrations
```

### Notes importantes

1. **Confluent Platform vs Apache Kafka** :
   - Ce projet utilise **Confluent Platform** (image `confluentinc/cp-kafka`)
   - Les commandes sont `kafka-topics` (sans `.sh`)
   - Pour Apache Kafka standard, les commandes seraient `kafka-topics.sh`

2. **Ports** :
   - **Kafka** : `localhost:9092` (depuis l'h√¥te)
   - **Kafka interne** : `kafka:29092` (depuis les autres conteneurs Docker)
   - **Zookeeper** : `localhost:2181`

3. **Auto-cr√©ation de topics** :
   - `KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"` est activ√© dans `docker-compose.yml`
   - Kafka cr√©era automatiquement le topic si un producer/consumer y acc√®de
   - Mais il est recommand√© de cr√©er le topic explicitement avec les bonnes configurations

4. **Persistence** :
   - Les donn√©es Kafka sont stock√©es dans le volume `kafka_data`
   - Les topics et messages persistent m√™me apr√®s un red√©marrage des conteneurs

### Prochaines √©tapes

1. ‚úÖ Topic `new_patient_registrations` cr√©√©
2. üîÑ Cr√©er le job Talend `job_stream_patient`
3. üîÑ Configurer `tKafkaInput` pour √©couter le topic
4. üîÑ Impl√©menter la logique de nettoyage et de lookup
5. üîÑ Tester le flux complet

