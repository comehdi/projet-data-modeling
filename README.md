# Projet Data Modeling - Master Data Management (MDM)

**Groupe Sant√© Horizon** - Consolidation des donn√©es de 3 cliniques h√©t√©rog√®nes

[![Docker](https://img.shields.io/badge/Docker-20.10+-blue.svg)](https://www.docker.com/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15-green.svg)](https://www.postgresql.org/)
[![Airflow](https://img.shields.io/badge/Airflow-2.8+-orange.svg)](https://airflow.apache.org/)
[![OpenMetadata](https://img.shields.io/badge/OpenMetadata-1.10.5-purple.svg)](https://open-metadata.org/)
[![Kafka](https://img.shields.io/badge/Kafka-7.5.0-black.svg)](https://kafka.apache.org/)

## üìã Table des mati√®res

- [Vue d'ensemble](#vue-densemble)
- [Architecture](#architecture)
- [Phases du projet](#phases-du-projet)
- [Pr√©requis](#pr√©requis)
- [Installation et d√©marrage](#installation-et-d√©marrage)
- [Acc√®s aux services](#acc√®s-aux-services)
- [Documentation](#documentation)
- [Structure du projet](#structure-du-projet)
- [Scripts utilitaires](#scripts-utilitaires)
- [D√©pannage](#d√©pannage)
  - [Guide de d√©pannage complet](#guide-de-d√©pannage-complet)
  - [Probl√®mes courants](#probl√®mes-courants)
  - [Documentation de d√©pannage](#documentation-de-d√©pannage)

## üéØ Vue d'ensemble

Ce projet impl√©mente une solution compl√®te de **Master Data Management (MDM)** pour le **Groupe Sant√© Horizon**, un groupe hospitalier form√© par la fusion de trois cliniques ind√©pendantes avec des syst√®mes d'information h√©t√©rog√®nes.

### Probl√©matique

La fusion de ces trois entit√©s a cr√©√© une situation critique de **perte de ma√Ætrise des donn√©es ma√Ætres** :
- **Duplication de patients** : Un m√™me patient enregistr√© 3 fois avec des informations diff√©rentes
- **Donn√©es incoh√©rentes** : Formats diff√©rents, valeurs manquantes, doublons
- **Risques m√©dicaux** : Allergies non visibles dans tous les syst√®mes
- **Facturation impossible** : Impossible de consolider les factures

### Solution

Mise en place d'un **MDM Hub** centralis√© avec :
- **4 Golden Tables** : Patient, Praticien, Service, Location
- **Pipelines ETL** : Nettoyage, d√©duplication, consolidation
- **Orchestration** : Airflow pour les batchs quotidiens
- **Streaming** : Kafka pour le temps r√©el
- **Gouvernance** : OpenMetadata pour le catalogue et la qualit√©

## üèóÔ∏è Architecture

![Project Architexture](https://github.com/comehdi/projet-data-modeling/blob/main/docs/MDM-Archi.png?raw=true)

### Services Docker

| Service | Port | Description |
|---------|------|-------------|
| **PostgreSQL MDM Hub** | 5432 | Base de donn√©es pour les Golden Tables |
| **Airflow** | 8081 | Orchestration des pipelines ETL (batch) |
| **OpenMetadata Server** | 8585 | Data Catalogue et Data Quality |
| **OpenMetadata Ingestion** | 8080 | Airflow interne pour l'ingestion |
| **Kafka** | 9092 | Streaming temps r√©el |
| **Zookeeper** | 2181 | Coordination pour Kafka |
| **Elasticsearch** | 9200 | Indexation pour OpenMetadata |

## üìö Phases du projet

### Phase 1 : Cadrage, Conception & R√©partition ‚úÖ

**Objectif** : D√©finir le p√©rim√®tre, le contexte et la structure des Golden Tables.

- **1.1** : Contexte & Probl√©matique
- **1.2** : R√©partition des domaines MDM (Patient, Praticien, Service, Location)
- **1.3** : Conception des tables ma√Ætres (sch√©mas SQL)

üìñ [Documentation Phase 1](docs/01-contexte-et-problematique.md)

### Phase 2 : Mise en Place de l'Environnement ‚úÖ

**Objectif** : Lancer toute l'infrastructure technique avec Docker.

- **2.1** : Cr√©ation du `docker-compose.yml`
- **2.2** : D√©finition des services (PostgreSQL, Airflow, OpenMetadata, Kafka)
- **2.3** : Lancement et initialisation

üìñ [Documentation Phase 2](docs/02-installation-et-demarrage.md)

### Phase 3 : Data Wrangling & Int√©gration ‚úÖ

**Objectif** : Construire les pipelines ETL qui nettoient, transforment et chargent les donn√©es.

- **3.1** : Simulation des donn√©es sources (CSV avec donn√©es "messy")
- **3.2** : Construction des jobs Talend (nettoyage, d√©duplication, consolidation)
- **3.3** : Orchestration batch avec Airflow (DAG `mdm_pipeline`)

### Phase 4 : Gouvernance, Data Catalogue & Data Quality ‚úÖ

**Objectif** : Documenter le travail et prouver la qualit√© des donn√©es avec OpenMetadata.

- **4.1** : Cr√©ation du Data Catalogue
- **4.2** : Cr√©ation du Dictionnaire de Donn√©es
- **4.3** : Configuration des m√©triques de Data Quality

üìñ [Documentation Phase 4](docs/05-phase-4-data-catalogue-quality.md)

### Phase 5 : Bonus - Streaming & Rapport ‚úÖ

**Objectif** : Montrer une ma√Ætrise avanc√©e avec le streaming temps r√©el.

- **5.1** : Impl√©mentation du flux temps r√©el (Kafka)
- **5.2** : R√©daction du rapport & expos√©

üìñ [Documentation Phase 5](docs/05-phase-5-kafka-streaming.md)

## üîß Pr√©requis

- **Docker** version 20.10 ou sup√©rieure
- **Docker Compose** version 2.0 ou sup√©rieure
- **8 GB de RAM** minimum (16 GB recommand√©)
- **20 GB d'espace disque** libre
- **PowerShell** (Windows) ou **Bash** (Linux/Mac)

### V√©rification des pr√©requis

```bash
# V√©rifier Docker
docker --version

# V√©rifier Docker Compose
docker-compose --version
```

## üöÄ Installation et d√©marrage

### 1. Cloner ou t√©l√©charger le projet

```bash
cd projet-data-modeling
```

### 2. D√©marrer les services de base

#### M√©thode 1 : Commandes de base (manuel)

**Linux/Mac/Windows (Git Bash)** :
```bash
# 1. Initialiser Airflow (premi√®re fois uniquement)
docker-compose --profile init up airflow-init

# 2. D√©marrer tous les services de base
docker-compose up -d postgres-mdm-hub zookeeper kafka airflow-db airflow-redis

# 3. Attendre que les services soient pr√™ts (10-15 secondes)
# V√©rifier les logs si n√©cessaire
docker-compose logs -f postgres-mdm-hub

# 4. D√©marrer Airflow (webserver et scheduler)
docker-compose up -d airflow-webserver airflow-scheduler

# 5. V√©rifier que tous les services sont d√©marr√©s
docker-compose ps
```

**Windows (PowerShell)** :
```powershell
# 1. Initialiser Airflow (premi√®re fois uniquement)
docker-compose --profile init up airflow-init

# 2. D√©marrer tous les services de base
docker-compose up -d postgres-mdm-hub zookeeper kafka airflow-db airflow-redis

# 3. Attendre que les services soient pr√™ts (10-15 secondes)
Start-Sleep -Seconds 15
# V√©rifier les logs si n√©cessaire
docker-compose logs -f postgres-mdm-hub

# 4. D√©marrer Airflow (webserver et scheduler)
docker-compose up -d airflow-webserver airflow-scheduler

# 5. V√©rifier que tous les services sont d√©marr√©s
docker-compose ps
```

**V√©rification** : V√©rifiez que tous les services sont d√©marr√©s :
```bash
docker-compose ps
```

Vous pouvez acc√©der √† :
- **Airflow** : http://localhost:8080 (admin/admin)
- **PostgreSQL MDM Hub** : localhost:5432 (postgres/root)

**Note** : Si vous rencontrez des erreurs avec les scripts, utilisez ces commandes de base.

#### M√©thode 2 : Utiliser les scripts (recommand√©)

**Windows (PowerShell)** :
```powershell
.\scripts\start-services.ps1
```

**Linux/Mac** :
```bash
chmod +x scripts/start-services.sh
./scripts/start-services.sh
```

### 3. D√©marrer OpenMetadata (Phase 4)

#### M√©thode 1 : Commandes de base (manuel)

**Linux/Mac/Windows (Git Bash)** :
```bash
# 1. D√©marrer les services de base n√©cessaires (PostgreSQL et Elasticsearch)
docker-compose --profile openmetadata up -d openmetadata-db elasticsearch

# 2. Attendre que les services soient pr√™ts (20-30 secondes)
sleep 20
# V√©rifier les logs
docker-compose --profile openmetadata logs -f openmetadata-db

# 3. Initialiser la base de donn√©es Airflow pour OpenMetadata
# Cr√©er la base de donn√©es et l'utilisateur
docker exec openmetadata-db psql -U postgres -c "CREATE DATABASE airflow_db;"
docker exec openmetadata-db psql -U postgres -c "CREATE USER airflow_user WITH PASSWORD 'airflow_pass';"
docker exec openmetadata-db psql -U postgres -c "GRANT ALL PRIVILEGES ON DATABASE airflow_db TO airflow_user;"

# 4. Lancer la migration OpenMetadata (une seule fois)
docker-compose --profile openmetadata-init up openmetadata-migrate

# 5. D√©marrer tous les services OpenMetadata
docker-compose --profile openmetadata up -d

# 6. V√©rifier que les services sont d√©marr√©s
docker-compose --profile openmetadata ps
```

**Windows (PowerShell)** :
```powershell
# 1. D√©marrer les services de base n√©cessaires (PostgreSQL et Elasticsearch)
docker-compose --profile openmetadata up -d openmetadata-db elasticsearch

# 2. Attendre que les services soient pr√™ts (20-30 secondes)
Start-Sleep -Seconds 30
# V√©rifier les logs
docker-compose --profile openmetadata logs -f openmetadata-db

# 3. Initialiser la base de donn√©es Airflow pour OpenMetadata
# Cr√©er la base de donn√©es et l'utilisateur
docker exec openmetadata-db psql -U postgres -c "CREATE DATABASE airflow_db;"
docker exec openmetadata-db psql -U postgres -c "CREATE USER airflow_user WITH PASSWORD 'airflow_pass';"
docker exec openmetadata-db psql -U postgres -c "GRANT ALL PRIVILEGES ON DATABASE airflow_db TO airflow_user;"

# 4. Lancer la migration OpenMetadata (une seule fois)
docker-compose --profile openmetadata-init up openmetadata-migrate

# 5. D√©marrer tous les services OpenMetadata
docker-compose --profile openmetadata up -d

# 6. V√©rifier que les services sont d√©marr√©s
docker-compose --profile openmetadata ps
```

**V√©rification** : V√©rifiez que les services OpenMetadata sont d√©marr√©s :
```bash
docker-compose --profile openmetadata ps
```

Vous pouvez acc√©der √† OpenMetadata √† l'adresse : http://localhost:8585

**Note** : Si vous rencontrez des erreurs avec les scripts, utilisez ces commandes de base.

#### M√©thode 2 : Utiliser les scripts (recommand√©)

**Windows (PowerShell)** :
```powershell
# Initialiser la base de donn√©es Airflow pour OpenMetadata
.\scripts\init-openmetadata-airflow.ps1

# Lancer la migration (une seule fois)
docker-compose --profile openmetadata-init up openmetadata-migrate

# D√©marrer OpenMetadata
docker-compose --profile openmetadata up -d
```

**Linux/Mac** :
```bash
# Initialiser la base de donn√©es Airflow
chmod +x scripts/init-openmetadata-airflow.sh
./scripts/init-openmetadata-airflow.sh

# Lancer la migration (une seule fois)
docker-compose --profile openmetadata-init up openmetadata-migrate

# D√©marrer OpenMetadata
docker-compose --profile openmetadata up -d
```

### 4. Cr√©er le topic Kafka (Phase 5)

#### M√©thode 1 : Commandes de base (manuel)

**Linux/Mac/Windows (Git Bash)** :
```bash
# 1. V√©rifier que Kafka est d√©marr√©
docker ps --filter "name=kafka"

# 2. Attendre que Kafka soit pr√™t (10-15 secondes)
sleep 15
# V√©rifier les logs si n√©cessaire
docker-compose logs -f kafka

# 3. Cr√©er le topic
docker exec kafka kafka-topics --create \
  --topic new_patient_registrations \
  --bootstrap-server localhost:9092 \
  --partitions 1 \
  --replication-factor 1

# 4. V√©rifier que le topic est cr√©√©
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092

# 5. Afficher les d√©tails du topic
docker exec kafka kafka-topics --describe \
  --topic new_patient_registrations \
  --bootstrap-server localhost:9092
```

**Windows (PowerShell)** :
```powershell
# 1. V√©rifier que Kafka est d√©marr√©
docker ps --filter "name=kafka"

# 2. Attendre que Kafka soit pr√™t (10-15 secondes)
Start-Sleep -Seconds 15
# V√©rifier les logs si n√©cessaire
docker-compose logs -f kafka

# 3. Cr√©er le topic
docker exec kafka kafka-topics --create `
  --topic new_patient_registrations `
  --bootstrap-server localhost:9092 `
  --partitions 1 `
  --replication-factor 1

# 4. V√©rifier que le topic est cr√©√©
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092

# 5. Afficher les d√©tails du topic
docker exec kafka kafka-topics --describe `
  --topic new_patient_registrations `
  --bootstrap-server localhost:9092
```

**V√©rification** : V√©rifiez que le topic est cr√©√© :
```bash
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092
```

Vous devriez voir `new_patient_registrations` dans la liste.

**Note** : Si vous rencontrez des erreurs avec les scripts, utilisez ces commandes de base.

#### M√©thode 2 : Utiliser les scripts (recommand√©)

**Windows (PowerShell)** :
```powershell
.\scripts\create-kafka-topic.ps1
```

**Linux/Mac** :
```bash
chmod +x scripts/create-kafka-topic.sh
./scripts/create-kafka-topic.sh
```

## üåê Acc√®s aux services

Une fois les services d√©marr√©s, vous pouvez acc√©der √† :

| Service | URL | Identifiants |
|---------|-----|--------------|
| **PostgreSQL MDM Hub** | `localhost:5432` | User: `postgres`<br>Password: `root`<br>Database: `mdm_clinique` |
| **Airflow** | http://localhost:8081 | User: `admin`<br>Password: `admin` |
| **OpenMetadata** | http://localhost:8585 | Email: `admin@open-metadata.org`<br>Password: `admin` |
| **OpenMetadata Ingestion** | http://localhost:8080 | User: `admin`<br>Password: `admin` |
| **Kafka** | `localhost:9092` | - |
| **Zookeeper** | `localhost:2181` | - |
| **Elasticsearch** | http://localhost:9200 | - |

## üìñ Documentation

### Documentation principale

- **[Phase 1 : Contexte & Probl√©matique](docs/01-contexte-et-problematique.md)** - Contexte du projet et probl√©matique MDM
- **[Phase 2 : Installation et D√©marrage](docs/02-installation-et-demarrage.md)** - Guide d'installation complet
- **[Phase 4 : Data Catalogue & Quality](docs/05-phase-4-data-catalogue-quality.md)** - Configuration OpenMetadata
- **[Phase 5 : Kafka Streaming](docs/05-phase-5-kafka-streaming.md)** - Impl√©mentation du streaming temps r√©el

### Guides de configuration

- **[Configuration OpenMetadata](docs/03-openmetadata-options.md)** - Options et configuration avanc√©e
- **[D√©pannage Airflow](docs/04-depannage-airflow.md)** - R√©solution des probl√®mes courants
- **[Configurer Pipeline Service](docs/configurer-pipeline-service-openmetadata.md)** - Configuration du service Pipeline
- **[Ingestion compl√®te avec donn√©es](docs/ingestion-complete-avec-donnees.md)** - Guide d'ingestion avec donn√©es

### Guides de d√©pannage

- **[Guide de D√©pannage Complet](docs/troubleshooting-guide.md)** - Liste compl√®te des probl√®mes et solutions
- **[Corriger Elasticsearch et Service](docs/corriger-elasticsearch-et-service.md)** - R√©solution des probl√®mes Elasticsearch
- **[Corriger Lineage Pipeline Database](docs/corriger-lineage-pipeline-database.md)** - R√©solution des probl√®mes de lineage
- **[Relancer ingestion colonnes vides](docs/relancer-ingestion-colonnes-vides.md)** - R√©solution des tables sans colonnes et configuration Profiler Agent
- **[Corriger Pipeline Service](docs/corriger-pipeline-service.md)** - Configuration Pipeline Service (PostgreSQL vs Airflow)
- **[Configurer Pipeline Service](docs/configurer-pipeline-service-openmetadata.md)** - Configuration Pipeline Service
- **[D√©pannage Airflow](docs/04-depannage-airflow.md)** - Probl√®mes courants Airflow

## üìÅ Structure du projet

```
projet-data-modeling/
‚îú‚îÄ‚îÄ airflow/                      # Configuration Airflow
‚îÇ   ‚îú‚îÄ‚îÄ dags/                    # DAGs Airflow
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ mdm_pipeline.py      # DAG principal pour les jobs Talend
‚îÇ   ‚îú‚îÄ‚îÄ config/                  # Scripts de configuration
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ init-talend.sh       # Script d'initialisation Talend
‚îÇ   ‚îî‚îÄ‚îÄ logs/                    # Logs Airflow
‚îú‚îÄ‚îÄ data/                        # Donn√©es sources (CSV)
‚îÇ   ‚îú‚îÄ‚îÄ clinique_A_patients.csv
‚îÇ   ‚îú‚îÄ‚îÄ clinique_B_patients.csv
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ sql/                         # Scripts SQL
‚îÇ   ‚îú‚îÄ‚îÄ 00-enable-pg-stat-statements.sql
‚îÇ   ‚îî‚îÄ‚îÄ 01-create-tables.sql     # Cr√©ation des Golden Tables
‚îú‚îÄ‚îÄ scripts/                     # Scripts utilitaires
‚îÇ   ‚îú‚îÄ‚îÄ start-services.ps1      # D√©marrage des services (Windows)
‚îÇ   ‚îú‚îÄ‚îÄ start-services.sh        # D√©marrage des services (Linux/Mac)
‚îÇ   ‚îú‚îÄ‚îÄ create-kafka-topic.ps1   # Cr√©ation du topic Kafka (Windows)
‚îÇ   ‚îú‚îÄ‚îÄ create-kafka-topic.sh    # Cr√©ation du topic Kafka (Linux/Mac)
‚îÇ   ‚îú‚îÄ‚îÄ init-openmetadata-airflow.ps1
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ talend_jobs/                 # Jobs Talend export√©s
‚îÇ   ‚îú‚îÄ‚îÄ job_master_patient/
‚îÇ   ‚îú‚îÄ‚îÄ job_master_praticien/
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ docs/                        # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ 01-contexte-et-problematique.md
‚îÇ   ‚îú‚îÄ‚îÄ 02-installation-et-demarrage.md
‚îÇ   ‚îú‚îÄ‚îÄ 05-phase-4-data-catalogue-quality.md
‚îÇ   ‚îî‚îÄ‚îÄ 05-phase-5-kafka-streaming.md
‚îú‚îÄ‚îÄ docker-compose.yml           # Configuration Docker Compose
‚îî‚îÄ‚îÄ README.md                    # Ce fichier
```

## üõ†Ô∏è Scripts utilitaires

### D√©marrage et arr√™t

- `start-services.ps1` / `start-services.sh` - D√©marrer tous les services
- `start-all-services.ps1` - D√©marrer tous les services avec v√©rifications
- `stop-services.sh` - Arr√™ter tous les services

### OpenMetadata

- `init-openmetadata-airflow.ps1` / `init-openmetadata-airflow.sh` - Initialiser Airflow pour OpenMetadata
- `start-openmetadata.ps1` / `start-openmetadata.sh` - D√©marrer OpenMetadata

### Kafka

- `create-kafka-topic.ps1` / `create-kafka-topic.sh` - Cr√©er le topic Kafka

### V√©rification

- `check-status.ps1` - V√©rifier l'√©tat de tous les services
- `verify-setup.ps1` - V√©rifier la configuration compl√®te

## üîç D√©pannage

### Guide de d√©pannage complet

Pour une liste compl√®te des probl√®mes courants et leurs solutions, consultez le **[Guide de D√©pannage Complet](docs/troubleshooting-guide.md)**.

### Probl√®mes courants

#### Les services ne d√©marrent pas

```bash
# V√©rifier les logs
docker-compose logs -f

# V√©rifier l'√©tat des services
docker-compose ps

# Red√©marrer un service sp√©cifique
docker-compose restart <service-name>
```

#### Erreur : "Failed to trigger workflow due to airflow API returned Internal Server Error" avec `localhost:8585`

**Cause** : L'Airflow d'ingestion essaie de se connecter au serveur OpenMetadata via `localhost:8585` au lieu d'utiliser le nom du conteneur Docker.

**Solution** : V√©rifiez que la variable d'environnement `SERVER_HOST_API_URL` est configur√©e dans `openmetadata-server` :

```bash
docker exec openmetadata-server env | grep SERVER_HOST_API_URL
```

Vous devriez voir : `SERVER_HOST_API_URL=http://openmetadata-server:8585/api`

Si ce n'est pas le cas, red√©marrez le conteneur :

```bash
docker-compose --profile openmetadata restart openmetadata-server
```

**Documentation d√©taill√©e** : Voir [Guide de D√©pannage](docs/troubleshooting-guide.md#erreur-failed-to-trigger-workflow-due-to-airflow-api-returned-internal-server-error-avec-connection-refused-sur-localhost8585) ou [Configuration OpenMetadata](docs/03-openmetadata-options.md)

#### Erreur : "Failed to fetch queries, please validate if postgres instance has pg_stat_statements extension installed"

**Cause** : L'extension `pg_stat_statements` n'est pas activ√©e dans PostgreSQL.

**Solution** : L'extension est automatiquement configur√©e dans `docker-compose.yml`. Si vous avez des probl√®mes :

```bash
# V√©rifier que l'extension est install√©e
docker exec postgres-mdm-hub psql -U postgres -d mdm_clinique -c "SELECT extname, extversion FROM pg_extension WHERE extname = 'pg_stat_statements';"

# Red√©marrer PostgreSQL si n√©cessaire
docker-compose restart postgres-mdm-hub
```

**Documentation d√©taill√©e** : Voir [Guide de D√©pannage](docs/troubleshooting-guide.md#erreur-failed-to-fetch-queries-please-validate-if-postgres-instance-has-pg_stat_statements-extension-installed) ou [Configuration OpenMetadata](docs/03-openmetadata-options.md)

#### Erreur : "No DAG run found"

**Cause** : Le pipeline d'ingestion n'a pas √©t√© ex√©cut√©. Le DAG existe mais aucun run n'a √©t√© cr√©√©.

**Solution** : D√©clencher manuellement le DAG via l'interface OpenMetadata ou Airflow :

```bash
# Via l'interface OpenMetadata
# Settings > Services > Databases > MDM Clinique Hub > Ingestion Pipelines > Run Now

# Via l'interface Airflow
# Ouvrez http://localhost:8080 > Trouvez votre DAG > Trigger DAG
```

**Documentation d√©taill√©e** : Voir [Guide de D√©pannage](docs/troubleshooting-guide.md#erreur-no-dag-run-found)

#### OpenMetadata ne se connecte pas √† Airflow

**Cause** : Le service `openmetadata-ingestion` n'est pas d√©marr√© ou la base de donn√©es Airflow n'est pas initialis√©e.

**Solution** :

1. **Initialiser la base de donn√©es Airflow** :
```powershell
.\scripts\init-openmetadata-airflow.ps1
```

2. **Red√©marrer le service** :
```bash
docker-compose --profile openmetadata restart openmetadata-ingestion
```

**Documentation d√©taill√©e** : Voir [Guide de D√©pannage](docs/troubleshooting-guide.md#erreur-failed-to-connect-to-airflow) ou [Configuration OpenMetadata](docs/03-openmetadata-options.md)

#### Tables vides dans OpenMetadata

**Sympt√¥me 1** : Les tables sont visibles mais n'ont pas de colonnes affich√©es.

**Solution** : Voir [Relancer ingestion colonnes vides](docs/relancer-ingestion-colonnes-vides.md)

**Sympt√¥me 2** : Les tables ont des colonnes mais pas de donn√©es d'√©chantillonnage (Sample Data).

**Solution** : Configurez et lancez le **Profiler Agent** dans OpenMetadata. Voir [Relancer ingestion colonnes vides](docs/relancer-ingestion-colonnes-vides.md#configurer-et-lancer-le-profiler-agent-pour-voir-les-donn√©es)

**Documentation d√©taill√©e** : Voir [Guide de D√©pannage](docs/troubleshooting-guide.md#tables-vides-dans-openmetadata)

#### Erreurs Elasticsearch

**Sympt√¥me** : `Search failed due to Elasticsearch exception [type=search_phase_execution_exception, reason=all shards failed]`

**Solution** :

```bash
# Red√©marrer Elasticsearch
docker-compose --profile openmetadata restart elasticsearch
Start-Sleep -Seconds 20

# Red√©marrer OpenMetadata Server
docker-compose --profile openmetadata restart openmetadata-server
Start-Sleep -Seconds 30
```

**Documentation d√©taill√©e** : Voir [Guide de D√©pannage](docs/troubleshooting-guide.md#erreur-search-failed-due-to-elasticsearch-exception) ou [Corriger Elasticsearch et Service](docs/corriger-elasticsearch-et-service.md)

#### Erreur : "relation serialized_dag does not exist"

**Cause** : Vous avez configur√© **PostgreSQL** comme **Pipeline Service** au lieu d'**Airflow**.

**Solution** : Voir [Corriger Pipeline Service](docs/corriger-pipeline-service.md)

**Documentation d√©taill√©e** : Voir [Guide de D√©pannage](docs/troubleshooting-guide.md#erreur-relation-serialized_dag-does-not-exist)

### Commandes utiles

```bash
# Voir les logs d'un service
docker-compose logs -f <service-name>

# Red√©marrer tous les services
docker-compose restart

# Arr√™ter tous les services
docker-compose down

# Arr√™ter et supprimer les volumes (‚ö†Ô∏è supprime les donn√©es)
docker-compose down -v

# V√©rifier l'utilisation des ressources
docker stats
```

### Documentation de d√©pannage

- **[Guide de D√©pannage Complet](docs/troubleshooting-guide.md)** - Liste compl√®te des probl√®mes et solutions
- [Configuration OpenMetadata](docs/03-openmetadata-options.md) - Configuration et d√©pannage OpenMetadata
- [D√©pannage Airflow](docs/04-depannage-airflow.md) - Probl√®mes courants Airflow
- [Relancer ingestion colonnes vides](docs/relancer-ingestion-colonnes-vides.md) - Tables vides et Profiler Agent
- [Corriger Elasticsearch et Service](docs/corriger-elasticsearch-et-service.md) - Probl√®mes Elasticsearch
- [Corriger Pipeline Service](docs/corriger-pipeline-service.md) - Configuration Pipeline Service
- [Corriger Lineage Pipeline Database](docs/corriger-lineage-pipeline-database.md) - Probl√®mes de lineage
- [Configurer Pipeline Service](docs/configurer-pipeline-service-openmetadata.md) - Configuration Pipeline Service

## üìä Golden Tables

Le projet impl√©mente 4 tables ma√Ætres (Golden Tables) :

1. **MDM_Patient** - Patients consolid√©s
2. **MDM_Praticien** - Praticiens consolid√©s
3. **MDM_Service** - Services/Actes consolid√©s
4. **MDM_Location** - Sites/Locations consolid√©s

Chaque table contient :
- Des champs "golden" normalis√©s et consolid√©s
- Un identifiant ma√Ætre unique (UUID)
- Des m√©tadonn√©es de tra√ßabilit√© (`source_system_ids`, `last_updated_at`)

## üéì Utilisation p√©dagogique

Ce projet est con√ßu pour :
- Comprendre les concepts de **Master Data Management (MDM)**
- Pratiquer le **Data Wrangling** avec Talend
- Apprendre l'**orchestration** avec Airflow
- D√©couvrir la **gouvernance des donn√©es** avec OpenMetadata
- Impl√©menter le **streaming temps r√©el** avec Kafka

## üìù Notes importantes

- **Ports** : Assurez-vous que les ports 5432, 8080, 8081, 8585, 9092, 2181, 9200 sont libres
- **Ressources** : OpenMetadata et Elasticsearch n√©cessitent au moins 2 GB de RAM chacun
- **Persistance** : Les donn√©es sont stock√©es dans des volumes Docker et persistent apr√®s red√©marrage
- **Profils Docker Compose** : Utilisez `--profile openmetadata` pour d√©marrer OpenMetadata s√©par√©ment

## ü§ù Contribution

Ce projet est un projet acad√©mique. Pour toute question ou suggestion, veuillez cr√©er une issue.

Un projet r√©alis√© par [OUGHEGI El Mehdi](https://github.com/comehdi) & [Mohammed Lamziouaq](https://github.com/medlamziouaq)

## üìÑ Licence


Ce projet est distribu√© sous la licence MIT et est destin√© √† un usage √©ducatif dans le cadre du cours de Data Modeling.

Consultez le fichier [LICENCE](LICENSE) pour plus de d√©tails.

---

**Groupe Sant√© Horizon** - Master Data Management Hub  
*Consolidation des donn√©es de 3 cliniques h√©t√©rog√®nes*
