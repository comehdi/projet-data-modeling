# Projet Data Modeling - Master Data Management (MDM)

**Groupe SantÃ© Horizon** - Consolidation des donnÃ©es de 3 cliniques hÃ©tÃ©rogÃ¨nes

[![Docker](https://img.shields.io/badge/Docker-20.10+-blue.svg)](https://www.docker.com/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15-green.svg)](https://www.postgresql.org/)
[![Airflow](https://img.shields.io/badge/Airflow-2.8+-orange.svg)](https://airflow.apache.org/)
[![OpenMetadata](https://img.shields.io/badge/OpenMetadata-1.10.5-purple.svg)](https://open-metadata.org/)
[![Kafka](https://img.shields.io/badge/Kafka-7.5.0-black.svg)](https://kafka.apache.org/)

## ğŸ“‹ Table des matiÃ¨res

- [Vue d'ensemble](#vue-densemble)
- [Architecture](#architecture)
- [Phases du projet](#phases-du-projet)
- [PrÃ©requis](#prÃ©requis)
- [Installation et dÃ©marrage](#installation-et-dÃ©marrage)
- [AccÃ¨s aux services](#accÃ¨s-aux-services)
- [Documentation](#documentation)
- [Structure du projet](#structure-du-projet)
- [Scripts utilitaires](#scripts-utilitaires)
- [DÃ©pannage](#dÃ©pannage)

## ğŸ¯ Vue d'ensemble

Ce projet implÃ©mente une solution complÃ¨te de **Master Data Management (MDM)** pour le **Groupe SantÃ© Horizon**, un groupe hospitalier formÃ© par la fusion de trois cliniques indÃ©pendantes avec des systÃ¨mes d'information hÃ©tÃ©rogÃ¨nes.

### ProblÃ©matique

La fusion de ces trois entitÃ©s a crÃ©Ã© une situation critique de **perte de maÃ®trise des donnÃ©es maÃ®tres** :
- **Duplication de patients** : Un mÃªme patient enregistrÃ© 3 fois avec des informations diffÃ©rentes
- **DonnÃ©es incohÃ©rentes** : Formats diffÃ©rents, valeurs manquantes, doublons
- **Risques mÃ©dicaux** : Allergies non visibles dans tous les systÃ¨mes
- **Facturation impossible** : Impossible de consolider les factures

### Solution

Mise en place d'un **MDM Hub** centralisÃ© avec :
- **4 Golden Tables** : Patient, Praticien, Service, Location
- **Pipelines ETL** : Nettoyage, dÃ©duplication, consolidation
- **Orchestration** : Airflow pour les batchs quotidiens
- **Streaming** : Kafka pour le temps rÃ©el
- **Gouvernance** : OpenMetadata pour le catalogue et la qualitÃ©

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Groupe SantÃ© Horizon                      â”‚
â”‚                  Master Data Management Hub                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                     â”‚                     â”‚
   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
   â”‚ Cliniqueâ”‚          â”‚ Clinique  â”‚         â”‚ Clinique â”‚
   â”‚    A    â”‚          â”‚    B      â”‚         â”‚    C     â”‚
   â”‚  (HIS)  â”‚          â”‚ (LABSYS)  â”‚         â”‚  (EMR)   â”‚
   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
        â”‚                     â”‚                     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Talend ETL Jobs â”‚
                    â”‚  (Data Wrangling) â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                     â”‚                     â”‚
   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
   â”‚ Airflow â”‚          â”‚ PostgreSQLâ”‚         â”‚  Kafka  â”‚
   â”‚ (Batch) â”‚          â”‚  MDM Hub â”‚         â”‚(Stream) â”‚
   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
        â”‚                     â”‚                     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   OpenMetadata     â”‚
                    â”‚ (Data Catalogue &  â”‚
                    â”‚   Data Quality)    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Services Docker

| Service | Port | Description |
|---------|------|-------------|
| **PostgreSQL MDM Hub** | 5432 | Base de donnÃ©es pour les Golden Tables |
| **Airflow** | 8081 | Orchestration des pipelines ETL (batch) |
| **OpenMetadata Server** | 8585 | Data Catalogue et Data Quality |
| **OpenMetadata Ingestion** | 8080 | Airflow interne pour l'ingestion |
| **Kafka** | 9092 | Streaming temps rÃ©el |
| **Zookeeper** | 2181 | Coordination pour Kafka |
| **Elasticsearch** | 9200 | Indexation pour OpenMetadata |

## ğŸ“š Phases du projet

### Phase 1 : Cadrage, Conception & RÃ©partition âœ…

**Objectif** : DÃ©finir le pÃ©rimÃ¨tre, le contexte et la structure des Golden Tables.

- **1.1** : Contexte & ProblÃ©matique
- **1.2** : RÃ©partition des domaines MDM (Patient, Praticien, Service, Location)
- **1.3** : Conception des tables maÃ®tres (schÃ©mas SQL)

ğŸ“– [Documentation Phase 1](docs/01-contexte-et-problematique.md)

### Phase 2 : Mise en Place de l'Environnement âœ…

**Objectif** : Lancer toute l'infrastructure technique avec Docker.

- **2.1** : CrÃ©ation du `docker-compose.yml`
- **2.2** : DÃ©finition des services (PostgreSQL, Airflow, OpenMetadata, Kafka)
- **2.3** : Lancement et initialisation

ğŸ“– [Documentation Phase 2](docs/02-installation-et-demarrage.md)

### Phase 3 : Data Wrangling & IntÃ©gration âœ…

**Objectif** : Construire les pipelines ETL qui nettoient, transforment et chargent les donnÃ©es.

- **3.1** : Simulation des donnÃ©es sources (CSV avec donnÃ©es "messy")
- **3.2** : Construction des jobs Talend (nettoyage, dÃ©duplication, consolidation)
- **3.3** : Orchestration batch avec Airflow (DAG `mdm_pipeline`)

### Phase 4 : Gouvernance, Data Catalogue & Data Quality âœ…

**Objectif** : Documenter le travail et prouver la qualitÃ© des donnÃ©es avec OpenMetadata.

- **4.1** : CrÃ©ation du Data Catalogue
- **4.2** : CrÃ©ation du Dictionnaire de DonnÃ©es
- **4.3** : Configuration des mÃ©triques de Data Quality

ğŸ“– [Documentation Phase 4](docs/05-phase-4-data-catalogue-quality.md)

### Phase 5 : Bonus - Streaming & Rapport âœ…

**Objectif** : Montrer une maÃ®trise avancÃ©e avec le streaming temps rÃ©el.

- **5.1** : ImplÃ©mentation du flux temps rÃ©el (Kafka)
- **5.2** : RÃ©daction du rapport & exposÃ©

ğŸ“– [Documentation Phase 5](docs/05-phase-5-kafka-streaming.md)

## ğŸ”§ PrÃ©requis

- **Docker** version 20.10 ou supÃ©rieure
- **Docker Compose** version 2.0 ou supÃ©rieure
- **8 GB de RAM** minimum (16 GB recommandÃ©)
- **20 GB d'espace disque** libre
- **PowerShell** (Windows) ou **Bash** (Linux/Mac)

### VÃ©rification des prÃ©requis

```bash
# VÃ©rifier Docker
docker --version

# VÃ©rifier Docker Compose
docker-compose --version
```

## ğŸš€ Installation et dÃ©marrage

### 1. Cloner ou tÃ©lÃ©charger le projet

```bash
cd projet-data-modeling
```

### 2. DÃ©marrer les services de base

#### MÃ©thode 1 : Commandes de base (manuel)

**Linux/Mac/Windows (Git Bash)** :
```bash
# 1. Initialiser Airflow (premiÃ¨re fois uniquement)
docker-compose --profile init up airflow-init

# 2. DÃ©marrer tous les services de base
docker-compose up -d postgres-mdm-hub zookeeper kafka airflow-db airflow-redis

# 3. Attendre que les services soient prÃªts (10-15 secondes)
# VÃ©rifier les logs si nÃ©cessaire
docker-compose logs -f postgres-mdm-hub

# 4. DÃ©marrer Airflow (webserver et scheduler)
docker-compose up -d airflow-webserver airflow-scheduler

# 5. VÃ©rifier que tous les services sont dÃ©marrÃ©s
docker-compose ps
```

**Windows (PowerShell)** :
```powershell
# 1. Initialiser Airflow (premiÃ¨re fois uniquement)
docker-compose --profile init up airflow-init

# 2. DÃ©marrer tous les services de base
docker-compose up -d postgres-mdm-hub zookeeper kafka airflow-db airflow-redis

# 3. Attendre que les services soient prÃªts (10-15 secondes)
Start-Sleep -Seconds 15
# VÃ©rifier les logs si nÃ©cessaire
docker-compose logs -f postgres-mdm-hub

# 4. DÃ©marrer Airflow (webserver et scheduler)
docker-compose up -d airflow-webserver airflow-scheduler

# 5. VÃ©rifier que tous les services sont dÃ©marrÃ©s
docker-compose ps
```

**VÃ©rification** : VÃ©rifiez que tous les services sont dÃ©marrÃ©s :
```bash
docker-compose ps
```

Vous pouvez accÃ©der Ã  :
- **Airflow** : http://localhost:8081 (admin/admin)
- **PostgreSQL MDM Hub** : localhost:5432 (postgres/root)

**Note** : Si vous rencontrez des erreurs avec les scripts, utilisez ces commandes de base.

#### MÃ©thode 2 : Utiliser les scripts (recommandÃ©)

**Windows (PowerShell)** :
```powershell
.\scripts\start-services.ps1
```

**Linux/Mac** :
```bash
chmod +x scripts/start-services.sh
./scripts/start-services.sh
```

### 3. DÃ©marrer OpenMetadata (Phase 4)

#### MÃ©thode 1 : Commandes de base (manuel)

**Linux/Mac/Windows (Git Bash)** :
```bash
# 1. DÃ©marrer les services de base nÃ©cessaires (PostgreSQL et Elasticsearch)
docker-compose --profile openmetadata up -d openmetadata-db elasticsearch

# 2. Attendre que les services soient prÃªts (20-30 secondes)
sleep 20
# VÃ©rifier les logs
docker-compose --profile openmetadata logs -f openmetadata-db

# 3. Initialiser la base de donnÃ©es Airflow pour OpenMetadata
# CrÃ©er la base de donnÃ©es et l'utilisateur
docker exec openmetadata-db psql -U postgres -c "CREATE DATABASE airflow_db;"
docker exec openmetadata-db psql -U postgres -c "CREATE USER airflow_user WITH PASSWORD 'airflow_pass';"
docker exec openmetadata-db psql -U postgres -c "GRANT ALL PRIVILEGES ON DATABASE airflow_db TO airflow_user;"

# 4. Lancer la migration OpenMetadata (une seule fois)
docker-compose --profile openmetadata-init up openmetadata-migrate

# 5. DÃ©marrer tous les services OpenMetadata
docker-compose --profile openmetadata up -d

# 6. VÃ©rifier que les services sont dÃ©marrÃ©s
docker-compose --profile openmetadata ps
```

**Windows (PowerShell)** :
```powershell
# 1. DÃ©marrer les services de base nÃ©cessaires (PostgreSQL et Elasticsearch)
docker-compose --profile openmetadata up -d openmetadata-db elasticsearch

# 2. Attendre que les services soient prÃªts (20-30 secondes)
Start-Sleep -Seconds 30
# VÃ©rifier les logs
docker-compose --profile openmetadata logs -f openmetadata-db

# 3. Initialiser la base de donnÃ©es Airflow pour OpenMetadata
# CrÃ©er la base de donnÃ©es et l'utilisateur
docker exec openmetadata-db psql -U postgres -c "CREATE DATABASE airflow_db;"
docker exec openmetadata-db psql -U postgres -c "CREATE USER airflow_user WITH PASSWORD 'airflow_pass';"
docker exec openmetadata-db psql -U postgres -c "GRANT ALL PRIVILEGES ON DATABASE airflow_db TO airflow_user;"

# 4. Lancer la migration OpenMetadata (une seule fois)
docker-compose --profile openmetadata-init up openmetadata-migrate

# 5. DÃ©marrer tous les services OpenMetadata
docker-compose --profile openmetadata up -d

# 6. VÃ©rifier que les services sont dÃ©marrÃ©s
docker-compose --profile openmetadata ps
```

**VÃ©rification** : VÃ©rifiez que les services OpenMetadata sont dÃ©marrÃ©s :
```bash
docker-compose --profile openmetadata ps
```

Vous pouvez accÃ©der Ã  OpenMetadata Ã  l'adresse : http://localhost:8585

**Note** : Si vous rencontrez des erreurs avec les scripts, utilisez ces commandes de base.

#### MÃ©thode 2 : Utiliser les scripts (recommandÃ©)

**Windows (PowerShell)** :
```powershell
# Initialiser la base de donnÃ©es Airflow pour OpenMetadata
.\scripts\init-openmetadata-airflow.ps1

# Lancer la migration (une seule fois)
docker-compose --profile openmetadata-init up openmetadata-migrate

# DÃ©marrer OpenMetadata
docker-compose --profile openmetadata up -d
```

**Linux/Mac** :
```bash
# Initialiser la base de donnÃ©es Airflow
chmod +x scripts/init-openmetadata-airflow.sh
./scripts/init-openmetadata-airflow.sh

# Lancer la migration (une seule fois)
docker-compose --profile openmetadata-init up openmetadata-migrate

# DÃ©marrer OpenMetadata
docker-compose --profile openmetadata up -d
```

### 4. CrÃ©er le topic Kafka (Phase 5)

#### MÃ©thode 1 : Commandes de base (manuel)

**Linux/Mac/Windows (Git Bash)** :
```bash
# 1. VÃ©rifier que Kafka est dÃ©marrÃ©
docker ps --filter "name=kafka"

# 2. Attendre que Kafka soit prÃªt (10-15 secondes)
sleep 15
# VÃ©rifier les logs si nÃ©cessaire
docker-compose logs -f kafka

# 3. CrÃ©er le topic
docker exec kafka kafka-topics --create \
  --topic new_patient_registrations \
  --bootstrap-server localhost:9092 \
  --partitions 1 \
  --replication-factor 1

# 4. VÃ©rifier que le topic est crÃ©Ã©
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092

# 5. Afficher les dÃ©tails du topic
docker exec kafka kafka-topics --describe \
  --topic new_patient_registrations \
  --bootstrap-server localhost:9092
```

**Windows (PowerShell)** :
```powershell
# 1. VÃ©rifier que Kafka est dÃ©marrÃ©
docker ps --filter "name=kafka"

# 2. Attendre que Kafka soit prÃªt (10-15 secondes)
Start-Sleep -Seconds 15
# VÃ©rifier les logs si nÃ©cessaire
docker-compose logs -f kafka

# 3. CrÃ©er le topic
docker exec kafka kafka-topics --create `
  --topic new_patient_registrations `
  --bootstrap-server localhost:9092 `
  --partitions 1 `
  --replication-factor 1

# 4. VÃ©rifier que le topic est crÃ©Ã©
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092

# 5. Afficher les dÃ©tails du topic
docker exec kafka kafka-topics --describe `
  --topic new_patient_registrations `
  --bootstrap-server localhost:9092
```

**VÃ©rification** : VÃ©rifiez que le topic est crÃ©Ã© :
```bash
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092
```

Vous devriez voir `new_patient_registrations` dans la liste.

**Note** : Si vous rencontrez des erreurs avec les scripts, utilisez ces commandes de base.

#### MÃ©thode 2 : Utiliser les scripts (recommandÃ©)

**Windows (PowerShell)** :
```powershell
.\scripts\create-kafka-topic.ps1
```

**Linux/Mac** :
```bash
chmod +x scripts/create-kafka-topic.sh
./scripts/create-kafka-topic.sh
```

## ğŸŒ AccÃ¨s aux services

Une fois les services dÃ©marrÃ©s, vous pouvez accÃ©der Ã  :

| Service | URL | Identifiants |
|---------|-----|--------------|
| **PostgreSQL MDM Hub** | `localhost:5432` | User: `postgres`<br>Password: `root`<br>Database: `mdm_clinique` |
| **Airflow** | http://localhost:8081 | User: `admin`<br>Password: `admin` |
| **OpenMetadata** | http://localhost:8585 | Email: `admin@open-metadata.org`<br>Password: `admin` |
| **OpenMetadata Ingestion** | http://localhost:8080 | User: `admin`<br>Password: `admin` |
| **Kafka** | `localhost:9092` | - |
| **Zookeeper** | `localhost:2181` | - |
| **Elasticsearch** | http://localhost:9200 | - |

## ğŸ“– Documentation

### Documentation principale

- **[Phase 1 : Contexte & ProblÃ©matique](docs/01-contexte-et-problematique.md)** - Contexte du projet et problÃ©matique MDM
- **[Phase 2 : Installation et DÃ©marrage](docs/02-installation-et-demarrage.md)** - Guide d'installation complet
- **[Phase 4 : Data Catalogue & Quality](docs/05-phase-4-data-catalogue-quality.md)** - Configuration OpenMetadata
- **[Phase 5 : Kafka Streaming](docs/05-phase-5-kafka-streaming.md)** - ImplÃ©mentation du streaming temps rÃ©el

### Guides de configuration

- **[Configuration OpenMetadata](docs/03-openmetadata-options.md)** - Options et configuration avancÃ©e
- **[DÃ©pannage Airflow](docs/04-depannage-airflow.md)** - RÃ©solution des problÃ¨mes courants
- **[Configurer Pipeline Service](docs/configurer-pipeline-service-openmetadata.md)** - Configuration du service Pipeline
- **[Ingestion complÃ¨te avec donnÃ©es](docs/ingestion-complete-avec-donnees.md)** - Guide d'ingestion avec donnÃ©es

### Guides de dÃ©pannage

- **[Corriger Elasticsearch et Service](docs/corriger-elasticsearch-et-service.md)** - RÃ©solution des problÃ¨mes Elasticsearch
- **[Corriger Lineage Pipeline Database](docs/corriger-lineage-pipeline-database.md)** - RÃ©solution des problÃ¨mes de lineage
- **[Relancer ingestion colonnes vides](docs/relancer-ingestion-colonnes-vides.md)** - RÃ©solution des tables sans colonnes

## ğŸ“ Structure du projet

```
projet-data-modeling/
â”œâ”€â”€ airflow/                      # Configuration Airflow
â”‚   â”œâ”€â”€ dags/                    # DAGs Airflow
â”‚   â”‚   â””â”€â”€ mdm_pipeline.py      # DAG principal pour les jobs Talend
â”‚   â”œâ”€â”€ config/                  # Scripts de configuration
â”‚   â”‚   â””â”€â”€ init-talend.sh       # Script d'initialisation Talend
â”‚   â””â”€â”€ logs/                    # Logs Airflow
â”œâ”€â”€ data/                        # DonnÃ©es sources (CSV)
â”‚   â”œâ”€â”€ clinique_A_patients.csv
â”‚   â”œâ”€â”€ clinique_B_patients.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ sql/                         # Scripts SQL
â”‚   â”œâ”€â”€ 00-enable-pg-stat-statements.sql
â”‚   â””â”€â”€ 01-create-tables.sql     # CrÃ©ation des Golden Tables
â”œâ”€â”€ scripts/                     # Scripts utilitaires
â”‚   â”œâ”€â”€ start-services.ps1      # DÃ©marrage des services (Windows)
â”‚   â”œâ”€â”€ start-services.sh        # DÃ©marrage des services (Linux/Mac)
â”‚   â”œâ”€â”€ create-kafka-topic.ps1   # CrÃ©ation du topic Kafka (Windows)
â”‚   â”œâ”€â”€ create-kafka-topic.sh    # CrÃ©ation du topic Kafka (Linux/Mac)
â”‚   â”œâ”€â”€ init-openmetadata-airflow.ps1
â”‚   â””â”€â”€ ...
â”œâ”€â”€ talend_jobs/                 # Jobs Talend exportÃ©s
â”‚   â”œâ”€â”€ job_master_patient/
â”‚   â”œâ”€â”€ job_master_praticien/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ docs/                        # Documentation
â”‚   â”œâ”€â”€ 01-contexte-et-problematique.md
â”‚   â”œâ”€â”€ 02-installation-et-demarrage.md
â”‚   â”œâ”€â”€ 05-phase-4-data-catalogue-quality.md
â”‚   â””â”€â”€ 05-phase-5-kafka-streaming.md
â”œâ”€â”€ docker-compose.yml           # Configuration Docker Compose
â””â”€â”€ README.md                    # Ce fichier
```

## ğŸ› ï¸ Scripts utilitaires

### DÃ©marrage et arrÃªt

- `start-services.ps1` / `start-services.sh` - DÃ©marrer tous les services
- `start-all-services.ps1` - DÃ©marrer tous les services avec vÃ©rifications
- `stop-services.sh` - ArrÃªter tous les services

### OpenMetadata

- `init-openmetadata-airflow.ps1` / `init-openmetadata-airflow.sh` - Initialiser Airflow pour OpenMetadata
- `start-openmetadata.ps1` / `start-openmetadata.sh` - DÃ©marrer OpenMetadata

### Kafka

- `create-kafka-topic.ps1` / `create-kafka-topic.sh` - CrÃ©er le topic Kafka

### VÃ©rification

- `check-status.ps1` - VÃ©rifier l'Ã©tat de tous les services
- `verify-setup.ps1` - VÃ©rifier la configuration complÃ¨te

## ğŸ” DÃ©pannage

### ProblÃ¨mes courants

#### Les services ne dÃ©marrent pas

```bash
# VÃ©rifier les logs
docker-compose logs -f

# VÃ©rifier l'Ã©tat des services
docker-compose ps

# RedÃ©marrer un service spÃ©cifique
docker-compose restart <service-name>
```

#### OpenMetadata ne se connecte pas Ã  Airflow

Voir [Corriger Lineage Pipeline Database](docs/corriger-lineage-pipeline-database.md)

#### Tables vides dans OpenMetadata

Voir [Relancer ingestion colonnes vides](docs/relancer-ingestion-colonnes-vides.md)

#### Erreurs Elasticsearch

Voir [Corriger Elasticsearch et Service](docs/corriger-elasticsearch-et-service.md)

### Commandes utiles

```bash
# Voir les logs d'un service
docker-compose logs -f <service-name>

# RedÃ©marrer tous les services
docker-compose restart

# ArrÃªter tous les services
docker-compose down

# ArrÃªter et supprimer les volumes (âš ï¸ supprime les donnÃ©es)
docker-compose down -v

# VÃ©rifier l'utilisation des ressources
docker stats
```

## ğŸ“Š Golden Tables

Le projet implÃ©mente 4 tables maÃ®tres (Golden Tables) :

1. **MDM_Patient** - Patients consolidÃ©s
2. **MDM_Praticien** - Praticiens consolidÃ©s
3. **MDM_Service** - Services/Actes consolidÃ©s
4. **MDM_Location** - Sites/Locations consolidÃ©s

Chaque table contient :
- Des champs "golden" normalisÃ©s et consolidÃ©s
- Un identifiant maÃ®tre unique (UUID)
- Des mÃ©tadonnÃ©es de traÃ§abilitÃ© (`source_system_ids`, `last_updated_at`)

## ğŸ“ Utilisation pÃ©dagogique

Ce projet est conÃ§u pour :
- Comprendre les concepts de **Master Data Management (MDM)**
- Pratiquer le **Data Wrangling** avec Talend
- Apprendre l'**orchestration** avec Airflow
- DÃ©couvrir la **gouvernance des donnÃ©es** avec OpenMetadata
- ImplÃ©menter le **streaming temps rÃ©el** avec Kafka

## ğŸ“ Notes importantes

- **Ports** : Assurez-vous que les ports 5432, 8080, 8081, 8585, 9092, 2181, 9200 sont libres
- **Ressources** : OpenMetadata et Elasticsearch nÃ©cessitent au moins 2 GB de RAM chacun
- **Persistance** : Les donnÃ©es sont stockÃ©es dans des volumes Docker et persistent aprÃ¨s redÃ©marrage
- **Profils Docker Compose** : Utilisez `--profile openmetadata` pour dÃ©marrer OpenMetadata sÃ©parÃ©ment

## ğŸ¤ Contribution

Ce projet est un projet acadÃ©mique. Pour toute question ou suggestion, veuillez crÃ©er une issue.

## ğŸ“„ Licence

Ce projet est destinÃ© Ã  un usage Ã©ducatif dans le cadre du cours de Data Modeling.

---

**Groupe SantÃ© Horizon** - Master Data Management Hub  
*Consolidation des donnÃ©es de 3 cliniques hÃ©tÃ©rogÃ¨nes*
